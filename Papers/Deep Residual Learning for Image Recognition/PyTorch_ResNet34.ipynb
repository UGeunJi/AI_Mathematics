{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNJGGzAZSBJKDSLXSUCPne4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["### ResNet34 모델 정의 및 인스턴스 초기화"],"metadata":{"id":"0m7WD1ecyqIV"}},{"cell_type":"code","execution_count":9,"metadata":{"id":"LXsm9o7dxcCs","executionInfo":{"status":"ok","timestamp":1677122724332,"user_tz":-540,"elapsed":601,"user":{"displayName":"우근","userId":"13959726526519675652"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.backends.cudnn as cudnn\n","import torch.optim as optim\n","import os\n","\n","class BasicBlock(nn.Module):\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(BasicBlock, self).__init__()\n","\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(planes)\n","            )\n","    \n","    def forward(self, x):\n","      out = F.relu(self.bn1(self.conv1(x)))\n","      out = self.bn2(self.conv2(out))\n","      out += self.shortcut(x)\n","      out = F.relu(out)\n","      return out\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_block, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 64\n","\n","        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.layer1 = self._make_layer(block, 64, num_block[0], stride=1)\n","        self.layer2 = self._make_layer(block, 128, num_block[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, num_block[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, num_block[3], stride=2)\n","        self.linear = nn.Linear(512, num_classes)\n","    \n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1] * (num_blocks - 1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = F.avg_pool2d(out, 4)\n","        out = out.view(out.size(0), -1)\n","        out = self.linear(out)\n","        return out\n","\n","\n","def ResNet34():\n","    return ResNet(BasicBlock, [3, 4, 6, 3])"]},{"cell_type":"markdown","source":["### 데이터셋(Dataset) 다운로드 및 불러오기"],"metadata":{"id":"VRfkQpIp2iug"}},{"cell_type":"code","source":["import torchvision\n","import torchvision.transforms as transforms\n","\n","transform_train = transforms.Compose([\n","    transforms.ToTensor(),\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","])\n","\n","train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform_train)\n","test_dataset = torchvision.datasets.MNIST(root='/data', train=False, download=True, transform=transform_test)\n","\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=4)"],"metadata":{"id":"xVmUaeSU2qT6","executionInfo":{"status":"ok","timestamp":1677122724869,"user_tz":-540,"elapsed":551,"user":{"displayName":"우근","userId":"13959726526519675652"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["### 환경 설정 및 학습(Training) 함수 정의"],"metadata":{"id":"14uOI7wE3u4W"}},{"cell_type":"code","source":["device = 'cuda'\n","\n","net = ResNet34()\n","net = net.to(device)\n","net = torch.nn.DataParallel(net)\n","cudnn.benchmark = True\n","\n","learning_rate = 0.01\n","file_name = 'resnet34_mnist.pt'\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0002)\n","\n","def train(epoch):\n","    print('\\n[ Train epoch: %d ]' % epoch)\n","    net.train()\n","    train_loss = 0\n","    correct = 0\n","    total = 0\n","    for batch_idx, (inputs, targets) in enumerate(train_loader):\n","        inputs, targets = inputs.to(device), targets.to(device)\n","        optimizer.zero_grad()\n","\n","        benign_outputs = net(inputs)\n","        loss = criterion(benign_outputs, targets)\n","        loss.backward()\n","\n","        optimizer.step()\n","        train_loss += loss.item()\n","        _, predicted = benign_outputs.max(1)\n","\n","        total += targets.size(0)\n","        correct += predicted.eq(targets).sum().item()\n","\n","        if batch_idx % 100 == 0:\n","            print('\\nCurrent batch: ', str(batch_idx))\n","            print('Current benign train accuracy: ', str(predicted.eq(targets).sum().item() / targets.size(0)))\n","            print('Current benign train loss: ', loss.item())\n","\n","    print('\\nTotal benign train accuracy: ', 100. * correct / total)\n","    print('Total benign train loss: ', train_loss)\n","\n","\n","def test(epoch):\n","    print('\\n[ Test epoch: %d ]' % epoch)\n","    net.eval()\n","    loss = 0\n","    correct = 0\n","    total = 0\n","\n","    for batch_idx, (inputs, targets) in enumerate(test_loader):\n","        inputs, targets = inputs.to(device), targets.to(device)\n","        total += targets.size(0)\n","\n","        outputs = net(inputs)\n","        loss += criterion(outputs, targets).item()\n","\n","        _, predicted = outputs.max(1)\n","        correct += predicted.eq(targets).sum().item()\n","\n","    print('\\nTest accuracy: ', 100 * correct / total)\n","    print('Test average loss: ', loss / total)    \n","\n","    state = {\n","        'net': net.state_dict()\n","    }\n","    if not os.path.isdir('checkpoint'):\n","        os.mkdir('checkpoint')\n","    torch.save(state, './checkpoint/' + file_name)\n","    print('Model Saved!')\n","\n","\n","def adjust_learning_rate(optimizer, epoch):\n","    lr = learning_rate\n","    if epoch >= 5:\n","        lr /= 10\n","    for param_group in optimizer.param_groups:\n","        param_group['lr'] = lr"],"metadata":{"id":"-_UIOHCp3yta","executionInfo":{"status":"ok","timestamp":1677122725377,"user_tz":-540,"elapsed":512,"user":{"displayName":"우근","userId":"13959726526519675652"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["### 학습(Training) 진행\n","- MNIST 데이터셋에 대하여 전체 10 epoch로 99.5% test accuracy를 시연할 수 있습니다."],"metadata":{"id":"s41STn0l7NWH"}},{"cell_type":"code","source":["for epoch in range(0, 10):\n","    adjust_learning_rate(optimizer, epoch)\n","    train(epoch)\n","    test(epoch)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uX3IMsL57Wjk","executionInfo":{"status":"ok","timestamp":1677123510186,"user_tz":-540,"elapsed":783926,"user":{"displayName":"우근","userId":"13959726526519675652"}},"outputId":"95e8b444-bb19-49e2-e33c-f4015b7f5455"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","[ Train epoch: 0 ]\n","\n","Current batch:  0\n","Current benign train accuracy:  0.1328125\n","Current benign train loss:  2.4011642932891846\n","\n","Current batch:  100\n","Current benign train accuracy:  0.96875\n","Current benign train loss:  0.09426526725292206\n","\n","Current batch:  200\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.016807954758405685\n","\n","Current batch:  300\n","Current benign train accuracy:  0.984375\n","Current benign train loss:  0.07160206139087677\n","\n","Current batch:  400\n","Current benign train accuracy:  0.984375\n","Current benign train loss:  0.0224874559789896\n","\n","Total benign train accuracy:  95.96\n","Total benign train loss:  60.02227466646582\n","\n","[ Test epoch: 0 ]\n","\n","Test accuracy:  98.09\n","Test average loss:  0.0006671470421599225\n","Model Saved!\n","\n","[ Train epoch: 1 ]\n","\n","Current batch:  0\n","Current benign train accuracy:  0.984375\n","Current benign train loss:  0.04143410921096802\n","\n","Current batch:  100\n","Current benign train accuracy:  0.9765625\n","Current benign train loss:  0.0623592846095562\n","\n","Current batch:  200\n","Current benign train accuracy:  0.9921875\n","Current benign train loss:  0.0305939931422472\n","\n","Current batch:  300\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.0029940023086965084\n","\n","Current batch:  400\n","Current benign train accuracy:  0.9765625\n","Current benign train loss:  0.10553820431232452\n","\n","Total benign train accuracy:  99.14833333333333\n","Total benign train loss:  12.699840291577857\n","\n","[ Test epoch: 1 ]\n","\n","Test accuracy:  99.14\n","Test average loss:  0.0002490574744078913\n","Model Saved!\n","\n","[ Train epoch: 2 ]\n","\n","Current batch:  0\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.015761852264404297\n","\n","Current batch:  100\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.000938238634262234\n","\n","Current batch:  200\n","Current benign train accuracy:  0.9921875\n","Current benign train loss:  0.01405873242765665\n","\n","Current batch:  300\n","Current benign train accuracy:  0.984375\n","Current benign train loss:  0.06364284455776215\n","\n","Current batch:  400\n","Current benign train accuracy:  0.984375\n","Current benign train loss:  0.03432833403348923\n","\n","Total benign train accuracy:  99.45333333333333\n","Total benign train loss:  8.122400691616349\n","\n","[ Test epoch: 2 ]\n","\n","Test accuracy:  99.15\n","Test average loss:  0.0002712964332080446\n","Model Saved!\n","\n","[ Train epoch: 3 ]\n","\n","Current batch:  0\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.0026370673440396786\n","\n","Current batch:  100\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.00208264053799212\n","\n","Current batch:  200\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.005042633041739464\n","\n","Current batch:  300\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.0023352066054940224\n","\n","Current batch:  400\n","Current benign train accuracy:  0.9921875\n","Current benign train loss:  0.044956743717193604\n","\n","Total benign train accuracy:  99.62666666666667\n","Total benign train loss:  5.7673395929450635\n","\n","[ Test epoch: 3 ]\n","\n","Test accuracy:  99.04\n","Test average loss:  0.00030727855623918\n","Model Saved!\n","\n","[ Train epoch: 4 ]\n","\n","Current batch:  0\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.00391740957275033\n","\n","Current batch:  100\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.00019723555305972695\n","\n","Current batch:  200\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.0038718122523278\n","\n","Current batch:  300\n","Current benign train accuracy:  0.9921875\n","Current benign train loss:  0.011563064530491829\n","\n","Current batch:  400\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.0008438347722403705\n","\n","Total benign train accuracy:  99.73833333333333\n","Total benign train loss:  3.759785031666979\n","\n","[ Test epoch: 4 ]\n","\n","Test accuracy:  99.32\n","Test average loss:  0.00022032267044542095\n","Model Saved!\n","\n","[ Train epoch: 5 ]\n","\n","Current batch:  0\n","Current benign train accuracy:  0.9921875\n","Current benign train loss:  0.021284928545355797\n","\n","Current batch:  100\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.000582407636102289\n","\n","Current batch:  200\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.0005214593838900328\n","\n","Current batch:  300\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.0026714010164141655\n","\n","Current batch:  400\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.0003229745489079505\n","\n","Total benign train accuracy:  99.925\n","Total benign train loss:  1.2631269902703934\n","\n","[ Test epoch: 5 ]\n","\n","Test accuracy:  99.52\n","Test average loss:  0.00013941191888552568\n","Model Saved!\n","\n","[ Train epoch: 6 ]\n","\n","Current batch:  0\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.00014841704978607595\n","\n","Current batch:  100\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.0002900044491980225\n","\n","Current batch:  200\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.0002447435981594026\n","\n","Current batch:  300\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.0029558995738625526\n","\n","Current batch:  400\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.0012641878565773368\n","\n","Total benign train accuracy:  99.98333333333333\n","Total benign train loss:  0.6238385468313936\n","\n","[ Test epoch: 6 ]\n","\n","Test accuracy:  99.56\n","Test average loss:  0.0001387171499067108\n","Model Saved!\n","\n","[ Train epoch: 7 ]\n","\n","Current batch:  0\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.001170599483884871\n","\n","Current batch:  100\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.0009741885587573051\n","\n","Current batch:  200\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.002746559912338853\n","\n","Current batch:  300\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.0006678112549707294\n","\n","Current batch:  400\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.0023405440151691437\n","\n","Total benign train accuracy:  99.98666666666666\n","Total benign train loss:  0.5201531885431905\n","\n","[ Test epoch: 7 ]\n","\n","Test accuracy:  99.56\n","Test average loss:  0.0001370882282886896\n","Model Saved!\n","\n","[ Train epoch: 8 ]\n","\n","Current batch:  0\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.000369725632481277\n","\n","Current batch:  100\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.0004807181248907\n","\n","Current batch:  200\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.003646543947979808\n","\n","Current batch:  300\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.00048036413500085473\n","\n","Current batch:  400\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.00018841058772522956\n","\n","Total benign train accuracy:  99.995\n","Total benign train loss:  0.3928009265655419\n","\n","[ Test epoch: 8 ]\n","\n","Test accuracy:  99.6\n","Test average loss:  0.00013358748037480835\n","Model Saved!\n","\n","[ Train epoch: 9 ]\n","\n","Current batch:  0\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.00045298898476175964\n","\n","Current batch:  100\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.0008362258085981011\n","\n","Current batch:  200\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.00022176104539539665\n","\n","Current batch:  300\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.0003667232231236994\n","\n","Current batch:  400\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.0005158157437108457\n","\n","Total benign train accuracy:  99.99333333333334\n","Total benign train loss:  0.36954185571084963\n","\n","[ Test epoch: 9 ]\n","\n","Test accuracy:  99.57\n","Test average loss:  0.00013680383705318491\n","Model Saved!\n"]}]}]}