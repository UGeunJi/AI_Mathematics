{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNNNHZepEBCZ4AX8zQiX1+h"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"LXsm9o7dxcCs","executionInfo":{"status":"ok","timestamp":1677256155499,"user_tz":-540,"elapsed":2165,"user":{"displayName":"우근","userId":"13959726526519675652"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision.transforms as transforms\n","import torchvision\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from torchvision import datasets, transforms\n","from torch.utils.data import Dataset,DataLoader\n","import torch.optim as optim\n","import copy\n","import sys, time\n","from torch.autograd import Variable"]},{"cell_type":"markdown","source":["### 데이터 분할"],"metadata":{"id":"2YsvT-DHY8Hp"}},{"cell_type":"code","source":["from keras.datasets import cifar10\n","(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n","\n","X_valid = X_train[40000:]\n","X_train = X_train[:40000]\n","y_valid = y_train[40000:]\n","y_train = y_train[:40000]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xVmUaeSU2qT6","executionInfo":{"status":"ok","timestamp":1677256175242,"user_tz":-540,"elapsed":19755,"user":{"displayName":"우근","userId":"13959726526519675652"}},"outputId":"de7b6de9-72e5-4a6d-9e24-3810fdaed131"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170498071/170498071 [==============================] - 14s 0us/step\n"]}]},{"cell_type":"code","source":["class compare_catdog_dataset():\n","    def __init__(self,li):\n","        self.li = li\n","        self.len_train = len(li[0])\n","        self.len_valid = len(li[1])\n","        self.len_test = len(li[2])\n","    def __call__(self):\n","        #draw plt\n","        label = ['train', 'valid','test']\n","        data = [self.len_train,self.len_valid,self.len_test]\n","        plt.rcParams[\"font.size\"] = 12\n","        plt.figure(figsize=(12,8))\n","\n","        x = np.arange(len(label))\n","\n","        plt.bar(x, [self.len_train,self.len_valid,self.len_test], label='data', width=0.3, color='#FFFF00')\n","        plt.legend()\n","        plt.xticks(x, label)\n","        plt.ylabel('Number of data')\n","        plt.title('Compare DATASETS')\n","        plt.show()\n","\n","show =compare_catdog_dataset([X_train,X_valid,X_test])\n","show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":503},"id":"syjNogDTHj7J","executionInfo":{"status":"ok","timestamp":1677256175246,"user_tz":-540,"elapsed":48,"user":{"displayName":"우근","userId":"13959726526519675652"}},"outputId":"182e3b2c-025b-4bd9-a62f-3dc62d3458e5"},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 864x576 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["### Aug Compose"],"metadata":{"id":"gT4oHiY1Y_6z"}},{"cell_type":"code","source":["\n","train_transform = transforms.Compose([transforms.ToPILImage(),\n","                                      transforms.RandomCrop(32, padding=3),\n","                                      transforms.RandomHorizontalFlip(),\n","                                      transforms.ToTensor(),\n","                                      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n","                                      ])\n","test_transform = transforms.Compose([transforms.ToTensor(),\n","                                     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n","                                     ])"],"metadata":{"id":"GdLdf0RuINCz","executionInfo":{"status":"ok","timestamp":1677256175254,"user_tz":-540,"elapsed":45,"user":{"displayName":"우근","userId":"13959726526519675652"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["### DataSet"],"metadata":{"id":"YrPE9xtXZL1B"}},{"cell_type":"code","source":["class cifar_Dataset(Dataset):\n","    def __init__(self,X,y, transform =None):\n","        self.transform = transform\n","        self.image_list = X\n","        self.label_list = y\n","\n","    def __len__(self):\n","        return len(self.label_list)\n","\n","    def __getitem__(self,idx):\n","        img = self.image_list[idx]\n","        label = self.label_list[idx][0]\n","        if self.transform:\n","            result = self.transform(img)\n","        return result, label"],"metadata":{"id":"lMygzmbxPwsm","executionInfo":{"status":"ok","timestamp":1677256175257,"user_tz":-540,"elapsed":45,"user":{"displayName":"우근","userId":"13959726526519675652"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["Trainset = cifar_Dataset(X = X_train,y = y_train, transform=train_transform)\n","Valset = cifar_Dataset(X = X_valid,y = y_valid, transform= test_transform)\n","Testset = cifar_Dataset(X = X_test, y = y_test, transform = test_transform)"],"metadata":{"id":"9ZTVMN21RYJs","executionInfo":{"status":"ok","timestamp":1677256175972,"user_tz":-540,"elapsed":758,"user":{"displayName":"우근","userId":"13959726526519675652"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["trainloader = torch.utils.data.DataLoader(Trainset, batch_size=32, shuffle=True, num_workers=1)\n","valloader = torch.utils.data.DataLoader(Valset, batch_size=32, shuffle=True, num_workers=1)\n","testloader = torch.utils.data.DataLoader(Testset, batch_size=32, shuffle=False, num_workers=1)"],"metadata":{"id":"O7Rj55EAUPz4","executionInfo":{"status":"ok","timestamp":1677256175973,"user_tz":-540,"elapsed":758,"user":{"displayName":"우근","userId":"13959726526519675652"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"],"metadata":{"id":"4zNU1v4pUP3T","executionInfo":{"status":"ok","timestamp":1677256175974,"user_tz":-540,"elapsed":9,"user":{"displayName":"우근","userId":"13959726526519675652"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["### 모델 생성"],"metadata":{"id":"QsFpijOYZRHZ"}},{"cell_type":"code","source":["class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(Bottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = F.relu(self.bn2(self.conv2(out)))\n","        out = self.bn3(self.conv3(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 64\n","\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n","        self.linear = nn.Linear(512*block.expansion, num_classes)\n","\n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = F.avg_pool2d(out, 4)\n","        out = out.view(out.size(0), -1)\n","        out = self.linear(out)\n","        return out\n","\n","\n","def ResNet18():\n","    return ResNet(BasicBlock, [2,2,2,2])\n","\n","def ResNet34():\n","    return ResNet(BasicBlock, [3,4,6,3])\n","\n","def ResNet50():\n","    return ResNet(Bottleneck, [3,4,6,3])\n","\n","def ResNet101():\n","    return ResNet(Bottleneck, [3,4,23,3])\n","\n","def ResNet152():\n","    return ResNet(Bottleneck, [3,8,36,3])\n","\n","\n","def test():\n","    net = ResNet101()\n","    y = net(torch.randn(1,3,32,32))\n","    print(y.size())"],"metadata":{"id":"N4gxY0jrUP6n","executionInfo":{"status":"ok","timestamp":1677256175974,"user_tz":-540,"elapsed":8,"user":{"displayName":"우근","userId":"13959726526519675652"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["model = ResNet101()\n","from torchsummary import summary\n","summary(model.cuda(), (3,32,32))\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iwwZ9M5zUZYK","executionInfo":{"status":"ok","timestamp":1677256189138,"user_tz":-540,"elapsed":13172,"user":{"displayName":"우근","userId":"13959726526519675652"}},"outputId":"bf5cd568-73e4-4494-e39c-045c0a55ad14"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 64, 32, 32]           1,728\n","       BatchNorm2d-2           [-1, 64, 32, 32]             128\n","            Conv2d-3           [-1, 64, 32, 32]           4,096\n","       BatchNorm2d-4           [-1, 64, 32, 32]             128\n","            Conv2d-5           [-1, 64, 32, 32]          36,864\n","       BatchNorm2d-6           [-1, 64, 32, 32]             128\n","            Conv2d-7          [-1, 256, 32, 32]          16,384\n","       BatchNorm2d-8          [-1, 256, 32, 32]             512\n","            Conv2d-9          [-1, 256, 32, 32]          16,384\n","      BatchNorm2d-10          [-1, 256, 32, 32]             512\n","       Bottleneck-11          [-1, 256, 32, 32]               0\n","           Conv2d-12           [-1, 64, 32, 32]          16,384\n","      BatchNorm2d-13           [-1, 64, 32, 32]             128\n","           Conv2d-14           [-1, 64, 32, 32]          36,864\n","      BatchNorm2d-15           [-1, 64, 32, 32]             128\n","           Conv2d-16          [-1, 256, 32, 32]          16,384\n","      BatchNorm2d-17          [-1, 256, 32, 32]             512\n","       Bottleneck-18          [-1, 256, 32, 32]               0\n","           Conv2d-19           [-1, 64, 32, 32]          16,384\n","      BatchNorm2d-20           [-1, 64, 32, 32]             128\n","           Conv2d-21           [-1, 64, 32, 32]          36,864\n","      BatchNorm2d-22           [-1, 64, 32, 32]             128\n","           Conv2d-23          [-1, 256, 32, 32]          16,384\n","      BatchNorm2d-24          [-1, 256, 32, 32]             512\n","       Bottleneck-25          [-1, 256, 32, 32]               0\n","           Conv2d-26          [-1, 128, 32, 32]          32,768\n","      BatchNorm2d-27          [-1, 128, 32, 32]             256\n","           Conv2d-28          [-1, 128, 16, 16]         147,456\n","      BatchNorm2d-29          [-1, 128, 16, 16]             256\n","           Conv2d-30          [-1, 512, 16, 16]          65,536\n","      BatchNorm2d-31          [-1, 512, 16, 16]           1,024\n","           Conv2d-32          [-1, 512, 16, 16]         131,072\n","      BatchNorm2d-33          [-1, 512, 16, 16]           1,024\n","       Bottleneck-34          [-1, 512, 16, 16]               0\n","           Conv2d-35          [-1, 128, 16, 16]          65,536\n","      BatchNorm2d-36          [-1, 128, 16, 16]             256\n","           Conv2d-37          [-1, 128, 16, 16]         147,456\n","      BatchNorm2d-38          [-1, 128, 16, 16]             256\n","           Conv2d-39          [-1, 512, 16, 16]          65,536\n","      BatchNorm2d-40          [-1, 512, 16, 16]           1,024\n","       Bottleneck-41          [-1, 512, 16, 16]               0\n","           Conv2d-42          [-1, 128, 16, 16]          65,536\n","      BatchNorm2d-43          [-1, 128, 16, 16]             256\n","           Conv2d-44          [-1, 128, 16, 16]         147,456\n","      BatchNorm2d-45          [-1, 128, 16, 16]             256\n","           Conv2d-46          [-1, 512, 16, 16]          65,536\n","      BatchNorm2d-47          [-1, 512, 16, 16]           1,024\n","       Bottleneck-48          [-1, 512, 16, 16]               0\n","           Conv2d-49          [-1, 128, 16, 16]          65,536\n","      BatchNorm2d-50          [-1, 128, 16, 16]             256\n","           Conv2d-51          [-1, 128, 16, 16]         147,456\n","      BatchNorm2d-52          [-1, 128, 16, 16]             256\n","           Conv2d-53          [-1, 512, 16, 16]          65,536\n","      BatchNorm2d-54          [-1, 512, 16, 16]           1,024\n","       Bottleneck-55          [-1, 512, 16, 16]               0\n","           Conv2d-56          [-1, 256, 16, 16]         131,072\n","      BatchNorm2d-57          [-1, 256, 16, 16]             512\n","           Conv2d-58            [-1, 256, 8, 8]         589,824\n","      BatchNorm2d-59            [-1, 256, 8, 8]             512\n","           Conv2d-60           [-1, 1024, 8, 8]         262,144\n","      BatchNorm2d-61           [-1, 1024, 8, 8]           2,048\n","           Conv2d-62           [-1, 1024, 8, 8]         524,288\n","      BatchNorm2d-63           [-1, 1024, 8, 8]           2,048\n","       Bottleneck-64           [-1, 1024, 8, 8]               0\n","           Conv2d-65            [-1, 256, 8, 8]         262,144\n","      BatchNorm2d-66            [-1, 256, 8, 8]             512\n","           Conv2d-67            [-1, 256, 8, 8]         589,824\n","      BatchNorm2d-68            [-1, 256, 8, 8]             512\n","           Conv2d-69           [-1, 1024, 8, 8]         262,144\n","      BatchNorm2d-70           [-1, 1024, 8, 8]           2,048\n","       Bottleneck-71           [-1, 1024, 8, 8]               0\n","           Conv2d-72            [-1, 256, 8, 8]         262,144\n","      BatchNorm2d-73            [-1, 256, 8, 8]             512\n","           Conv2d-74            [-1, 256, 8, 8]         589,824\n","      BatchNorm2d-75            [-1, 256, 8, 8]             512\n","           Conv2d-76           [-1, 1024, 8, 8]         262,144\n","      BatchNorm2d-77           [-1, 1024, 8, 8]           2,048\n","       Bottleneck-78           [-1, 1024, 8, 8]               0\n","           Conv2d-79            [-1, 256, 8, 8]         262,144\n","      BatchNorm2d-80            [-1, 256, 8, 8]             512\n","           Conv2d-81            [-1, 256, 8, 8]         589,824\n","      BatchNorm2d-82            [-1, 256, 8, 8]             512\n","           Conv2d-83           [-1, 1024, 8, 8]         262,144\n","      BatchNorm2d-84           [-1, 1024, 8, 8]           2,048\n","       Bottleneck-85           [-1, 1024, 8, 8]               0\n","           Conv2d-86            [-1, 256, 8, 8]         262,144\n","      BatchNorm2d-87            [-1, 256, 8, 8]             512\n","           Conv2d-88            [-1, 256, 8, 8]         589,824\n","      BatchNorm2d-89            [-1, 256, 8, 8]             512\n","           Conv2d-90           [-1, 1024, 8, 8]         262,144\n","      BatchNorm2d-91           [-1, 1024, 8, 8]           2,048\n","       Bottleneck-92           [-1, 1024, 8, 8]               0\n","           Conv2d-93            [-1, 256, 8, 8]         262,144\n","      BatchNorm2d-94            [-1, 256, 8, 8]             512\n","           Conv2d-95            [-1, 256, 8, 8]         589,824\n","      BatchNorm2d-96            [-1, 256, 8, 8]             512\n","           Conv2d-97           [-1, 1024, 8, 8]         262,144\n","      BatchNorm2d-98           [-1, 1024, 8, 8]           2,048\n","       Bottleneck-99           [-1, 1024, 8, 8]               0\n","          Conv2d-100            [-1, 256, 8, 8]         262,144\n","     BatchNorm2d-101            [-1, 256, 8, 8]             512\n","          Conv2d-102            [-1, 256, 8, 8]         589,824\n","     BatchNorm2d-103            [-1, 256, 8, 8]             512\n","          Conv2d-104           [-1, 1024, 8, 8]         262,144\n","     BatchNorm2d-105           [-1, 1024, 8, 8]           2,048\n","      Bottleneck-106           [-1, 1024, 8, 8]               0\n","          Conv2d-107            [-1, 256, 8, 8]         262,144\n","     BatchNorm2d-108            [-1, 256, 8, 8]             512\n","          Conv2d-109            [-1, 256, 8, 8]         589,824\n","     BatchNorm2d-110            [-1, 256, 8, 8]             512\n","          Conv2d-111           [-1, 1024, 8, 8]         262,144\n","     BatchNorm2d-112           [-1, 1024, 8, 8]           2,048\n","      Bottleneck-113           [-1, 1024, 8, 8]               0\n","          Conv2d-114            [-1, 256, 8, 8]         262,144\n","     BatchNorm2d-115            [-1, 256, 8, 8]             512\n","          Conv2d-116            [-1, 256, 8, 8]         589,824\n","     BatchNorm2d-117            [-1, 256, 8, 8]             512\n","          Conv2d-118           [-1, 1024, 8, 8]         262,144\n","     BatchNorm2d-119           [-1, 1024, 8, 8]           2,048\n","      Bottleneck-120           [-1, 1024, 8, 8]               0\n","          Conv2d-121            [-1, 256, 8, 8]         262,144\n","     BatchNorm2d-122            [-1, 256, 8, 8]             512\n","          Conv2d-123            [-1, 256, 8, 8]         589,824\n","     BatchNorm2d-124            [-1, 256, 8, 8]             512\n","          Conv2d-125           [-1, 1024, 8, 8]         262,144\n","     BatchNorm2d-126           [-1, 1024, 8, 8]           2,048\n","      Bottleneck-127           [-1, 1024, 8, 8]               0\n","          Conv2d-128            [-1, 256, 8, 8]         262,144\n","     BatchNorm2d-129            [-1, 256, 8, 8]             512\n","          Conv2d-130            [-1, 256, 8, 8]         589,824\n","     BatchNorm2d-131            [-1, 256, 8, 8]             512\n","          Conv2d-132           [-1, 1024, 8, 8]         262,144\n","     BatchNorm2d-133           [-1, 1024, 8, 8]           2,048\n","      Bottleneck-134           [-1, 1024, 8, 8]               0\n","          Conv2d-135            [-1, 256, 8, 8]         262,144\n","     BatchNorm2d-136            [-1, 256, 8, 8]             512\n","          Conv2d-137            [-1, 256, 8, 8]         589,824\n","     BatchNorm2d-138            [-1, 256, 8, 8]             512\n","          Conv2d-139           [-1, 1024, 8, 8]         262,144\n","     BatchNorm2d-140           [-1, 1024, 8, 8]           2,048\n","      Bottleneck-141           [-1, 1024, 8, 8]               0\n","          Conv2d-142            [-1, 256, 8, 8]         262,144\n","     BatchNorm2d-143            [-1, 256, 8, 8]             512\n","          Conv2d-144            [-1, 256, 8, 8]         589,824\n","     BatchNorm2d-145            [-1, 256, 8, 8]             512\n","          Conv2d-146           [-1, 1024, 8, 8]         262,144\n","     BatchNorm2d-147           [-1, 1024, 8, 8]           2,048\n","      Bottleneck-148           [-1, 1024, 8, 8]               0\n","          Conv2d-149            [-1, 256, 8, 8]         262,144\n","     BatchNorm2d-150            [-1, 256, 8, 8]             512\n","          Conv2d-151            [-1, 256, 8, 8]         589,824\n","     BatchNorm2d-152            [-1, 256, 8, 8]             512\n","          Conv2d-153           [-1, 1024, 8, 8]         262,144\n","     BatchNorm2d-154           [-1, 1024, 8, 8]           2,048\n","      Bottleneck-155           [-1, 1024, 8, 8]               0\n","          Conv2d-156            [-1, 256, 8, 8]         262,144\n","     BatchNorm2d-157            [-1, 256, 8, 8]             512\n","          Conv2d-158            [-1, 256, 8, 8]         589,824\n","     BatchNorm2d-159            [-1, 256, 8, 8]             512\n","          Conv2d-160           [-1, 1024, 8, 8]         262,144\n","     BatchNorm2d-161           [-1, 1024, 8, 8]           2,048\n","      Bottleneck-162           [-1, 1024, 8, 8]               0\n","          Conv2d-163            [-1, 256, 8, 8]         262,144\n","     BatchNorm2d-164            [-1, 256, 8, 8]             512\n","          Conv2d-165            [-1, 256, 8, 8]         589,824\n","     BatchNorm2d-166            [-1, 256, 8, 8]             512\n","          Conv2d-167           [-1, 1024, 8, 8]         262,144\n","     BatchNorm2d-168           [-1, 1024, 8, 8]           2,048\n","      Bottleneck-169           [-1, 1024, 8, 8]               0\n","          Conv2d-170            [-1, 256, 8, 8]         262,144\n","     BatchNorm2d-171            [-1, 256, 8, 8]             512\n","          Conv2d-172            [-1, 256, 8, 8]         589,824\n","     BatchNorm2d-173            [-1, 256, 8, 8]             512\n","          Conv2d-174           [-1, 1024, 8, 8]         262,144\n","     BatchNorm2d-175           [-1, 1024, 8, 8]           2,048\n","      Bottleneck-176           [-1, 1024, 8, 8]               0\n","          Conv2d-177            [-1, 256, 8, 8]         262,144\n","     BatchNorm2d-178            [-1, 256, 8, 8]             512\n","          Conv2d-179            [-1, 256, 8, 8]         589,824\n","     BatchNorm2d-180            [-1, 256, 8, 8]             512\n","          Conv2d-181           [-1, 1024, 8, 8]         262,144\n","     BatchNorm2d-182           [-1, 1024, 8, 8]           2,048\n","      Bottleneck-183           [-1, 1024, 8, 8]               0\n","          Conv2d-184            [-1, 256, 8, 8]         262,144\n","     BatchNorm2d-185            [-1, 256, 8, 8]             512\n","          Conv2d-186            [-1, 256, 8, 8]         589,824\n","     BatchNorm2d-187            [-1, 256, 8, 8]             512\n","          Conv2d-188           [-1, 1024, 8, 8]         262,144\n","     BatchNorm2d-189           [-1, 1024, 8, 8]           2,048\n","      Bottleneck-190           [-1, 1024, 8, 8]               0\n","          Conv2d-191            [-1, 256, 8, 8]         262,144\n","     BatchNorm2d-192            [-1, 256, 8, 8]             512\n","          Conv2d-193            [-1, 256, 8, 8]         589,824\n","     BatchNorm2d-194            [-1, 256, 8, 8]             512\n","          Conv2d-195           [-1, 1024, 8, 8]         262,144\n","     BatchNorm2d-196           [-1, 1024, 8, 8]           2,048\n","      Bottleneck-197           [-1, 1024, 8, 8]               0\n","          Conv2d-198            [-1, 256, 8, 8]         262,144\n","     BatchNorm2d-199            [-1, 256, 8, 8]             512\n","          Conv2d-200            [-1, 256, 8, 8]         589,824\n","     BatchNorm2d-201            [-1, 256, 8, 8]             512\n","          Conv2d-202           [-1, 1024, 8, 8]         262,144\n","     BatchNorm2d-203           [-1, 1024, 8, 8]           2,048\n","      Bottleneck-204           [-1, 1024, 8, 8]               0\n","          Conv2d-205            [-1, 256, 8, 8]         262,144\n","     BatchNorm2d-206            [-1, 256, 8, 8]             512\n","          Conv2d-207            [-1, 256, 8, 8]         589,824\n","     BatchNorm2d-208            [-1, 256, 8, 8]             512\n","          Conv2d-209           [-1, 1024, 8, 8]         262,144\n","     BatchNorm2d-210           [-1, 1024, 8, 8]           2,048\n","      Bottleneck-211           [-1, 1024, 8, 8]               0\n","          Conv2d-212            [-1, 256, 8, 8]         262,144\n","     BatchNorm2d-213            [-1, 256, 8, 8]             512\n","          Conv2d-214            [-1, 256, 8, 8]         589,824\n","     BatchNorm2d-215            [-1, 256, 8, 8]             512\n","          Conv2d-216           [-1, 1024, 8, 8]         262,144\n","     BatchNorm2d-217           [-1, 1024, 8, 8]           2,048\n","      Bottleneck-218           [-1, 1024, 8, 8]               0\n","          Conv2d-219            [-1, 512, 8, 8]         524,288\n","     BatchNorm2d-220            [-1, 512, 8, 8]           1,024\n","          Conv2d-221            [-1, 512, 4, 4]       2,359,296\n","     BatchNorm2d-222            [-1, 512, 4, 4]           1,024\n","          Conv2d-223           [-1, 2048, 4, 4]       1,048,576\n","     BatchNorm2d-224           [-1, 2048, 4, 4]           4,096\n","          Conv2d-225           [-1, 2048, 4, 4]       2,097,152\n","     BatchNorm2d-226           [-1, 2048, 4, 4]           4,096\n","      Bottleneck-227           [-1, 2048, 4, 4]               0\n","          Conv2d-228            [-1, 512, 4, 4]       1,048,576\n","     BatchNorm2d-229            [-1, 512, 4, 4]           1,024\n","          Conv2d-230            [-1, 512, 4, 4]       2,359,296\n","     BatchNorm2d-231            [-1, 512, 4, 4]           1,024\n","          Conv2d-232           [-1, 2048, 4, 4]       1,048,576\n","     BatchNorm2d-233           [-1, 2048, 4, 4]           4,096\n","      Bottleneck-234           [-1, 2048, 4, 4]               0\n","          Conv2d-235            [-1, 512, 4, 4]       1,048,576\n","     BatchNorm2d-236            [-1, 512, 4, 4]           1,024\n","          Conv2d-237            [-1, 512, 4, 4]       2,359,296\n","     BatchNorm2d-238            [-1, 512, 4, 4]           1,024\n","          Conv2d-239           [-1, 2048, 4, 4]       1,048,576\n","     BatchNorm2d-240           [-1, 2048, 4, 4]           4,096\n","      Bottleneck-241           [-1, 2048, 4, 4]               0\n","          Linear-242                   [-1, 10]          20,490\n","================================================================\n","Total params: 42,512,970\n","Trainable params: 42,512,970\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 100.13\n","Params size (MB): 162.17\n","Estimated Total Size (MB): 262.31\n","----------------------------------------------------------------\n"]}]},{"cell_type":"markdown","source":["### Train & Test"],"metadata":{"id":"z6E0pqbsZX3Q"}},{"cell_type":"code","source":["class TrainModel():\n","    def __init__(self,model, criterion, optimizer, trainloader, testloader, num_epochs=5):\n","        \n","        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","        self.model = model.to(self.device)\n","        self.trainloader =trainloader\n","        self.testloader = testloader\n","        self.criterion = criterion\n","        self.optimizer = optimizer\n","        self.num_epochs = num_epochs\n","        self.best_acc_wts = copy.deepcopy(self.model.state_dict())\n","        self.best_acc =0.0\n","\n","        \n","        for epoch in range(1, self.num_epochs+1):\n","            print('Epoch {}/{}'.format(epoch, self.num_epochs))\n","            self.train()\n","            self.test()\n","\n","        model.load_state_dict(self.best_acc_wts)\n","\n","    def train(self):\n","        self.model.train()\n","        train_loss = 0\n","        correct = 0\n","        total = 0\n","        for batch_idx, (inputs, targets) in enumerate(self.trainloader):\n","            inputs, targets = inputs.to(self.device), targets.to(self.device)\n","            self.optimizer.zero_grad()\n","            outputs = self.model(inputs)\n","            loss = self.criterion(outputs, targets.long())\n","            loss.backward()\n","            self.optimizer.step()\n","\n","            train_loss += loss.data.cpu().numpy()\n","            _, predicted = outputs.max(1)\n","            total += targets.size(0)\n","            correct += predicted.eq(targets).sum().item()\n","\n","        epoch_loss = train_loss /len(self.trainloader)\n","        epoch_acc = correct / total\n","        print('train | Loss: {:.4f} Acc: {:.4f}'.format( epoch_loss, epoch_acc))\n","\n","    def test(self):\n","        global best_acc\n","        self.model.eval()\n","        test_loss = 0\n","        correct = 0\n","        total = 0\n","        with torch.no_grad():\n","            for batch_idx, (inputs, targets) in enumerate(self.testloader):\n","                inputs, targets = inputs.to(self.device), targets.to(self.device)\n","                outputs = self.model(inputs)\n","                loss = self.criterion(outputs, targets.long())\n","\n","                test_loss += loss.data.cpu().numpy()\n","                _, predicted = outputs.max(1)\n","                total += targets.size(0)\n","                correct += predicted.eq(targets).sum().item()\n","\n","            epoch_loss = test_loss /len(self.testloader)\n","            epoch_acc = correct / total\n","            print('test | Loss: {:.4f} Acc: {:.4f}'.format( epoch_loss, epoch_acc))\n","            if epoch_acc >= self.best_acc:\n","                self.best_acc = epoch_acc\n","                self.best_acc_wts = copy.deepcopy(self.model.state_dict())"],"metadata":{"id":"_AXNC-46Ub_4","executionInfo":{"status":"ok","timestamp":1677256189138,"user_tz":-540,"elapsed":11,"user":{"displayName":"우근","userId":"13959726526519675652"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["TrainModel(model, criterion=criterion, optimizer=optimizer,trainloader=trainloader,testloader=valloader,num_epochs=30)"],"metadata":{"id":"OsckQffiUcDM","executionInfo":{"status":"ok","timestamp":1677263716923,"user_tz":-540,"elapsed":7527794,"user":{"displayName":"우근","userId":"13959726526519675652"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0229f8d2-14f7-456c-d762-bdfc776027da"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","train | Loss: 1.9592 Acc: 0.2909\n","test | Loss: 1.6053 Acc: 0.4291\n","Epoch 2/30\n","train | Loss: 1.4889 Acc: 0.4521\n","test | Loss: 1.2577 Acc: 0.5362\n","Epoch 3/30\n","train | Loss: 1.2036 Acc: 0.5688\n","test | Loss: 1.2546 Acc: 0.6139\n","Epoch 4/30\n","train | Loss: 1.0060 Acc: 0.6443\n","test | Loss: 0.9658 Acc: 0.6623\n","Epoch 5/30\n","train | Loss: 0.8629 Acc: 0.6971\n","test | Loss: 0.8904 Acc: 0.7456\n","Epoch 6/30\n","train | Loss: 0.7437 Acc: 0.7418\n","test | Loss: 0.6982 Acc: 0.7603\n","Epoch 7/30\n","train | Loss: 0.6548 Acc: 0.7748\n","test | Loss: 0.5836 Acc: 0.7977\n","Epoch 8/30\n","train | Loss: 0.5814 Acc: 0.7998\n","test | Loss: 0.5745 Acc: 0.8098\n","Epoch 9/30\n","train | Loss: 0.5376 Acc: 0.8160\n","test | Loss: 0.5187 Acc: 0.8255\n","Epoch 10/30\n","train | Loss: 0.4937 Acc: 0.8311\n","test | Loss: 0.4640 Acc: 0.8421\n","Epoch 11/30\n","train | Loss: 0.4717 Acc: 0.8381\n","test | Loss: 0.4559 Acc: 0.8444\n","Epoch 12/30\n","train | Loss: 0.4451 Acc: 0.8473\n","test | Loss: 0.4561 Acc: 0.8381\n","Epoch 13/30\n","train | Loss: 0.4212 Acc: 0.8536\n","test | Loss: 0.4453 Acc: 0.8465\n","Epoch 14/30\n","train | Loss: 0.4003 Acc: 0.8623\n","test | Loss: 0.4022 Acc: 0.8626\n","Epoch 15/30\n","train | Loss: 0.3852 Acc: 0.8670\n","test | Loss: 0.4285 Acc: 0.8534\n","Epoch 16/30\n","train | Loss: 0.3691 Acc: 0.8735\n","test | Loss: 0.3943 Acc: 0.8641\n","Epoch 17/30\n","train | Loss: 0.3536 Acc: 0.8766\n","test | Loss: 0.3968 Acc: 0.8697\n","Epoch 18/30\n","train | Loss: 0.3449 Acc: 0.8832\n","test | Loss: 0.3703 Acc: 0.8711\n","Epoch 19/30\n","train | Loss: 0.3280 Acc: 0.8860\n","test | Loss: 0.3946 Acc: 0.8675\n","Epoch 20/30\n","train | Loss: 0.3250 Acc: 0.8860\n","test | Loss: 0.3432 Acc: 0.8835\n","Epoch 21/30\n","train | Loss: 0.3186 Acc: 0.8901\n","test | Loss: 0.4085 Acc: 0.8649\n","Epoch 22/30\n","train | Loss: 0.3074 Acc: 0.8939\n","test | Loss: 0.3973 Acc: 0.8685\n","Epoch 23/30\n","train | Loss: 0.2984 Acc: 0.8982\n","test | Loss: 0.3933 Acc: 0.8681\n","Epoch 24/30\n","train | Loss: 0.2901 Acc: 0.8995\n","test | Loss: 0.4039 Acc: 0.8676\n","Epoch 25/30\n","train | Loss: 0.2855 Acc: 0.9009\n","test | Loss: 0.3371 Acc: 0.8857\n","Epoch 26/30\n","train | Loss: 0.2790 Acc: 0.9038\n","test | Loss: 0.3258 Acc: 0.8917\n","Epoch 27/30\n","train | Loss: 0.2744 Acc: 0.9068\n","test | Loss: 0.3236 Acc: 0.8922\n","Epoch 28/30\n","train | Loss: 0.2667 Acc: 0.9081\n","test | Loss: 0.3470 Acc: 0.8835\n","Epoch 29/30\n","train | Loss: 0.2599 Acc: 0.9100\n","test | Loss: 0.3531 Acc: 0.8862\n","Epoch 30/30\n","train | Loss: 0.2569 Acc: 0.9112\n","test | Loss: 0.3059 Acc: 0.8955\n"]},{"output_type":"execute_result","data":{"text/plain":["<__main__.TrainModel at 0x7f06d29904f0>"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["def test(model,testloader,criterion):\n","        model.eval()\n","        test_loss = 0\n","        correct = 0\n","        total = 0\n","        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","        with torch.no_grad():\n","            for batch_idx, (inputs, targets) in enumerate(testloader):\n","                inputs,targets = inputs.to(device), targets.to(device)\n","                outputs = model(inputs)\n","                loss = criterion(outputs, targets.long())     \n","\n","                test_loss += loss.data.cpu().numpy()\n","                _, predicted = outputs.max(1)\n","                total += targets.size(0)\n","                correct += predicted.eq(targets).sum().item()\n","                \n","            epoch_loss = test_loss / len(testloader)\n","            epoch_acc = correct / total\n","            print('test | Loss: {:.4f} Acc: {:.4f}'.format( epoch_loss, epoch_acc))\n","\n","test(model,testloader,criterion)"],"metadata":{"id":"UM-4kRgyUcHK","executionInfo":{"status":"ok","timestamp":1677263733769,"user_tz":-540,"elapsed":16852,"user":{"displayName":"우근","userId":"13959726526519675652"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"87935299-d3f6-4d04-ac95-0c446b2d0b9c"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["test | Loss: 0.3349 Acc: 0.8891\n"]}]}]}