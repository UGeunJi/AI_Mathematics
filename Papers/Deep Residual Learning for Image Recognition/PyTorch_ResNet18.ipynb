{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNCEJBiet/epzon+xKMbRQZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["### ResNet18 모델 정의 및 인스턴스 초기화"],"metadata":{"id":"0m7WD1ecyqIV"}},{"cell_type":"code","execution_count":18,"metadata":{"id":"LXsm9o7dxcCs","executionInfo":{"status":"ok","timestamp":1677118322199,"user_tz":-540,"elapsed":2,"user":{"displayName":"우근","userId":"13959726526519675652"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.backends.cudnn as cudnn\n","import torch.optim as optim\n","import os\n","\n","# ResNet18을 위해 최대한 간단히 수정한 BasicBlock 클래스 정의\n","class BasicBlock(nn.Module):\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(BasicBlock, self).__init__()\n","\n","        # 3x3 필터를 사용 (너비와 높이를 줄일 때는 stride 값 조절)\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes) # 배치 정규화(Batch normalization)\n","\n","        # 3x3 필터를 사용 (패딩을 1만큼 주기 때문에 너비와 높이가 동일)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes) # 배치 정규화(Batch normalization)\n","\n","        self.shortcut = nn.Sequential() # identity인 경우\n","        if stride != 1: # stride가 1이 아니라면, Identity mapping이 아닌 경우\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(planes)\n","            )\n","    \n","    def forward(self, x):\n","      out = F.relu(self.bn1(self.conv1(x)))\n","      out = self.bn2(self.conv2(out))\n","      out += self.shortcut(x) # (핵심) skip connection\n","      out = F.relu(out)\n","      return out\n","\n","# ResNet 클래스 정의\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_block, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 64\n","\n","        # 64개의 3x3 필터(filter)를 사용\n","        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.layer1 = self._make_layer(block, 64, num_block[0], stride=1)\n","        self.layer2 = self._make_layer(block, 128, num_block[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, num_block[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, num_block[3], stride=2)\n","        self.linear = nn.Linear(512, num_classes)\n","    \n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1] * (num_blocks - 1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes # 다음 레이어를 위해 채널 수 변경\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = F.avg_pool2d(out, 4)\n","        out = out.view(out.size(0), -1)\n","        out = self.linear(out)\n","        return out\n","\n","\n","# ResNet18 함수 정의\n","def ResNet18():\n","    return ResNet(BasicBlock, [2, 2, 2, 2])"]},{"cell_type":"markdown","source":["### 데이터셋(Dataset) 다운로드 및 불러오기"],"metadata":{"id":"VRfkQpIp2iug"}},{"cell_type":"code","source":["import torchvision\n","import torchvision.transforms as transforms\n","\n","transform_train = transforms.Compose([\n","    transforms.ToTensor(),\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","])\n","\n","train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform_train)\n","test_dataset = torchvision.datasets.MNIST(root='/data', train=False, download=True, transform=transform_test)\n","\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xVmUaeSU2qT6","executionInfo":{"status":"ok","timestamp":1677118322718,"user_tz":-540,"elapsed":10,"user":{"displayName":"우근","userId":"13959726526519675652"}},"outputId":"c54385c0-fe42-4330-fae9-e3f309083d5a"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}]},{"cell_type":"markdown","source":["### 환경 설정 및 학습(Training) 함수 정의"],"metadata":{"id":"14uOI7wE3u4W"}},{"cell_type":"code","source":["device = 'cuda'\n","\n","net = ResNet18()\n","net = net.to(device)\n","net = torch.nn.DataParallel(net)\n","cudnn.benchmark = True\n","\n","learning_rate = 0.01\n","file_name = 'resnet18_mnist.pt'\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0002)\n","\n","def train(epoch):\n","    print('\\n[ Train epoch: %d ]' % epoch)\n","    net.train()\n","    train_loss = 0\n","    correct = 0\n","    total = 0\n","    for batch_idx, (inputs, targets) in enumerate(train_loader):\n","        inputs, targets = inputs.to(device), targets.to(device)\n","        optimizer.zero_grad()\n","\n","        benign_outputs = net(inputs)\n","        loss = criterion(benign_outputs, targets)\n","        loss.backward()\n","\n","        optimizer.step()\n","        train_loss += loss.item()\n","        _, predicted = benign_outputs.max(1)\n","\n","        total += targets.size(0)\n","        correct += predicted.eq(targets).sum().item()\n","\n","        if batch_idx % 100 == 0:\n","            print('\\nCurrent batch: ', str(batch_idx))\n","            print('Current benign train accuracy: ', str(predicted.eq(targets).sum().item() / targets.size(0)))\n","            print('Current benign train loss: ', loss.item())\n","\n","    print('\\nTotal benign train accuracy: ', 100. * correct / total)\n","    print('Total benign train loss: ', train_loss)\n","\n","\n","def test(epoch):\n","    print('\\n[ Test epoch: %d ]' % epoch)\n","    net.eval()\n","    loss = 0\n","    correct = 0\n","    total = 0\n","\n","    for batch_idx, (inputs, targets) in enumerate(test_loader):\n","        inputs, targets = inputs.to(device), targets.to(device)\n","        total += targets.size(0)\n","\n","        outputs = net(inputs)\n","        loss += criterion(outputs, targets).item()\n","\n","        _, predicted = outputs.max(1)\n","        correct += predicted.eq(targets).sum().item()\n","\n","    print('\\nTest accuracy: ', 100 * correct / total)\n","    print('Test average loss: ', loss / total)    \n","\n","    state = {\n","        'net': net.state_dict()\n","    }\n","    if not os.path.isdir('checkpoint'):\n","        os.mkdir('checkpoint')\n","    torch.save(state, './checkpoint/' + file_name)\n","    print('Model Saved!')\n","\n","\n","def adjust_learning_rate(optimizer, epoch):\n","    lr = learning_rate\n","    if epoch >= 5:\n","        lr /= 10\n","    for param_group in optimizer.param_groups:\n","        param_group['lr'] = lr"],"metadata":{"id":"-_UIOHCp3yta","executionInfo":{"status":"ok","timestamp":1677118323125,"user_tz":-540,"elapsed":5,"user":{"displayName":"우근","userId":"13959726526519675652"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["### 학습(Training) 진행\n","- MNIST 데이터셋에 대하여 전체 10 epoch로 99.5% test accuracy를 시연할 수 있습니다."],"metadata":{"id":"s41STn0l7NWH"}},{"cell_type":"code","source":["for epoch in range(0, 10):\n","    adjust_learning_rate(optimizer, epoch)\n","    train(epoch)\n","    test(epoch)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uX3IMsL57Wjk","executionInfo":{"status":"ok","timestamp":1677118750857,"user_tz":-540,"elapsed":427736,"user":{"displayName":"우근","userId":"13959726526519675652"}},"outputId":"616f4819-35eb-47e4-a63a-c606b8ae4faa"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","[ Train epoch: 0 ]\n","\n","Current batch:  0\n","Current benign train accuracy:  0.125\n","Current benign train loss:  2.3227317333221436\n","\n","Current batch:  100\n","Current benign train accuracy:  0.984375\n","Current benign train loss:  0.092360720038414\n","\n","Current batch:  200\n","Current benign train accuracy:  0.9921875\n","Current benign train loss:  0.01886468194425106\n","\n","Current batch:  300\n","Current benign train accuracy:  0.9921875\n","Current benign train loss:  0.05716964974999428\n","\n","Current batch:  400\n","Current benign train accuracy:  0.9921875\n","Current benign train loss:  0.06492284685373306\n","\n","Total benign train accuracy:  96.00333333333333\n","Total benign train loss:  58.627654497977346\n","\n","[ Test epoch: 0 ]\n","\n","Test accuracy:  97.92\n","Test average loss:  0.0006325421893619933\n","Model Saved!\n","\n","[ Train epoch: 1 ]\n","\n","Current batch:  0\n","Current benign train accuracy:  0.9921875\n","Current benign train loss:  0.03265443444252014\n","\n","Current batch:  100\n","Current benign train accuracy:  0.9765625\n","Current benign train loss:  0.07204915583133698\n","\n","Current batch:  200\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.007353397086262703\n","\n","Current batch:  300\n","Current benign train accuracy:  0.9765625\n","Current benign train loss:  0.06816703826189041\n","\n","Current batch:  400\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.011345011182129383\n","\n","Total benign train accuracy:  99.21833333333333\n","Total benign train loss:  12.079249755945057\n","\n","[ Test epoch: 1 ]\n","\n","Test accuracy:  99.06\n","Test average loss:  0.0003256193656416144\n","Model Saved!\n","\n","[ Train epoch: 2 ]\n","\n","Current batch:  0\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.00926323514431715\n","\n","Current batch:  100\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.005810107104480267\n","\n","Current batch:  200\n","Current benign train accuracy:  0.9921875\n","Current benign train loss:  0.048249825835227966\n","\n","Current batch:  300\n","Current benign train accuracy:  0.9765625\n","Current benign train loss:  0.04577507823705673\n","\n","Current batch:  400\n","Current benign train accuracy:  0.9921875\n","Current benign train loss:  0.019704068079590797\n","\n","Total benign train accuracy:  99.52333333333333\n","Total benign train loss:  7.250514149258379\n","\n","[ Test epoch: 2 ]\n","\n","Test accuracy:  99.37\n","Test average loss:  0.00021328224481458163\n","Model Saved!\n","\n","[ Train epoch: 3 ]\n","\n","Current batch:  0\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.008834188804030418\n","\n","Current batch:  100\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.001121890963986516\n","\n","Current batch:  200\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.009223563596606255\n","\n","Current batch:  300\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.0027614899445325136\n","\n","Current batch:  400\n","Current benign train accuracy:  0.9921875\n","Current benign train loss:  0.010762865655124187\n","\n","Total benign train accuracy:  99.79833333333333\n","Total benign train loss:  3.5367803457629634\n","\n","[ Test epoch: 3 ]\n","\n","Test accuracy:  99.33\n","Test average loss:  0.0001815638996220514\n","Model Saved!\n","\n","[ Train epoch: 4 ]\n","\n","Current batch:  0\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.004191577434539795\n","\n","Current batch:  100\n","Current benign train accuracy:  0.9921875\n","Current benign train loss:  0.015506920404732227\n","\n","Current batch:  200\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.0002507728640921414\n","\n","Current batch:  300\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.00036923467996530235\n","\n","Current batch:  400\n","Current benign train accuracy:  0.9921875\n","Current benign train loss:  0.009002132341265678\n","\n","Total benign train accuracy:  99.90166666666667\n","Total benign train loss:  1.7930192823405378\n","\n","[ Test epoch: 4 ]\n","\n","Test accuracy:  99.31\n","Test average loss:  0.00022738495934972888\n","Model Saved!\n","\n","[ Train epoch: 5 ]\n","\n","Current batch:  0\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.005872771609574556\n","\n","Current batch:  100\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.0017230049706995487\n","\n","Current batch:  200\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.0007530757575295866\n","\n","Current batch:  300\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.00043211239972151816\n","\n","Current batch:  400\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.00022140168584883213\n","\n","Total benign train accuracy:  99.95333333333333\n","Total benign train loss:  0.9610220673857839\n","\n","[ Test epoch: 5 ]\n","\n","Test accuracy:  99.51\n","Test average loss:  0.00015154068416641168\n","Model Saved!\n","\n","[ Train epoch: 6 ]\n","\n","Current batch:  0\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.0006427240441553295\n","\n","Current batch:  100\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.00017752517305780202\n","\n","Current batch:  200\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.0013742981245741248\n","\n","Current batch:  300\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.00038285867776721716\n","\n","Current batch:  400\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.0047213914804160595\n","\n","Total benign train accuracy:  99.99166666666666\n","Total benign train loss:  0.4629128874912567\n","\n","[ Test epoch: 6 ]\n","\n","Test accuracy:  99.49\n","Test average loss:  0.00015045564707761515\n","Model Saved!\n","\n","[ Train epoch: 7 ]\n","\n","Current batch:  0\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.00038155229412950575\n","\n","Current batch:  100\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.00046152889262884855\n","\n","Current batch:  200\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.0004989220178686082\n","\n","Current batch:  300\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.0006841109716333449\n","\n","Current batch:  400\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.00031770826899446547\n","\n","Total benign train accuracy:  99.99333333333334\n","Total benign train loss:  0.41297512433084194\n","\n","[ Test epoch: 7 ]\n","\n","Test accuracy:  99.5\n","Test average loss:  0.0001441079865950087\n","Model Saved!\n","\n","[ Train epoch: 8 ]\n","\n","Current batch:  0\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.00038095374475233257\n","\n","Current batch:  100\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.0009158639004454017\n","\n","Current batch:  200\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.0003060408344026655\n","\n","Current batch:  300\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.0007739250431768596\n","\n","Current batch:  400\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.0013233685167506337\n","\n","Total benign train accuracy:  99.99833333333333\n","Total benign train loss:  0.33472387633810285\n","\n","[ Test epoch: 8 ]\n","\n","Test accuracy:  99.55\n","Test average loss:  0.00014334045159448578\n","Model Saved!\n","\n","[ Train epoch: 9 ]\n","\n","Current batch:  0\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.0005411638994701207\n","\n","Current batch:  100\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.0002666476066224277\n","\n","Current batch:  200\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.0005882469704374671\n","\n","Current batch:  300\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.0002523580624256283\n","\n","Current batch:  400\n","Current benign train accuracy:  1.0\n","Current benign train loss:  0.0006971433758735657\n","\n","Total benign train accuracy:  99.99833333333333\n","Total benign train loss:  0.31362550267294864\n","\n","[ Test epoch: 9 ]\n","\n","Test accuracy:  99.54\n","Test average loss:  0.00014007189340040896\n","Model Saved!\n"]}]}]}
